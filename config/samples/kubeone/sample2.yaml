apiVersion: terraform.kubeterra.io/v1alpha1
kind: TerraformConfiguration
metadata:
  name: sample2
  namespace: kubeterra-system
spec:
  autoApprove: true
  template:
    # for debug purposes uncomment the following
    # env:
    # - name: TF_LOG
    #   value: "TRACE"
    envFrom:
    - secretRef:
        name: hetzner-credentials
    volumes:
    - name: scripts
      configMap:
        name: hetzner-scripts
    - name: secrets
      secret:
        secretName: hetzner-secrets
    volumeMounts:
    - name: scripts
      mountPath: /scripts
    - name: secrets
      mountPath: /secrets

  values: |
    cluster_name         = "kubeterra1"
    datacenter           = "nbg1"
    files_prefix         = "/scripts/"
    ssh_public_key_file  = "/secrets/id_rsa.pub"
    ssh_private_key_file = "/secrets/id_rsa"

  configuration: |
    variable "cluster_name" {
      description = "prefix for cloud resources"
    }

    variable "worker_os" {
      description = "OS to run on worker machines"

      # valid choices are:
      # * ubuntu
      # * centos
      # * coreos
      default = "ubuntu"
    }

    variable "ssh_public_key_file" {
      description = "SSH public key file"
      default     = "~/.ssh/id_rsa.pub"
    }

    variable "ssh_port" {
      description = "SSH port to be used to provision instances"
      default     = 22
    }

    variable "ssh_username" {
      description = "SSH user, used only in output"
      default     = "root"
    }

    variable "ssh_private_key_file" {
      description = "SSH private key file used to access instances"
      default     = ""
    }

    variable "ssh_agent_socket" {
      description = "SSH Agent socket, default to grab from $SSH_AUTH_SOCK"
      default     = "env:SSH_AUTH_SOCK"
    }

    # Provider specific settings

    variable "control_plane_type" {
      default = "cx21"
    }

    variable "worker_type" {
      default = "cx21"
    }

    variable "lb_type" {
      default = "cx11"
    }

    variable "datacenter" {
      default = "fsn1"
    }

    variable "image" {
      default = "ubuntu-18.04"
    }

    variable "files_prefix" {
      default     = ""
      description = "File system path to files"
    }

    resource "hcloud_ssh_key" "kubeone" {
      name       = "kubeone-${var.cluster_name}"
      public_key = file(var.ssh_public_key_file)
    }

    resource "hcloud_server" "control_plane" {
      count       = 3
      name        = "${var.cluster_name}-control-plane-${count.index + 1}"
      server_type = var.control_plane_type
      image       = var.image
      location    = var.datacenter

      ssh_keys = [
        hcloud_ssh_key.kubeone.id,
      ]

      labels = {
        "kubeone_cluster_name" = var.cluster_name
        "role"                 = "api"
      }
    }

    resource "hcloud_server" "lb" {
      name        = "${var.cluster_name}-lb"
      server_type = var.lb_type
      image       = var.image
      location    = var.datacenter

      ssh_keys = [
        hcloud_ssh_key.kubeone.id,
      ]

      labels = {
        "kubeone_cluster_name" = var.cluster_name
        "role"                 = "lb"
      }

      connection {
        type        = "ssh"
        private_key = file(var.ssh_private_key_file)
        host        = self.ipv4_address
      }

      provisioner "remote-exec" {
        script = "${var.files_prefix}gobetween.sh"
      }
    }

    locals {
      rendered_lb_config = templatefile("${var.files_prefix}etc_gobetween.tpl", {
        lb_targets = hcloud_server.control_plane.*.ipv4_address,
      })
    }

    resource "null_resource" "lb_config" {
      triggers = {
        cluster_instance_ids = join(",", hcloud_server.control_plane.*.id)
        config               = local.rendered_lb_config
      }

      connection {
        type        = "ssh"
        private_key = file(var.ssh_private_key_file)
        host        = hcloud_server.lb.ipv4_address
      }

      provisioner "file" {
        content     = local.rendered_lb_config
        destination = "/etc/gobetween.toml"
      }

      provisioner "remote-exec" {
        inline = [
          "systemctl restart gobetween",
        ]
      }
    }

    output "kubeone_api" {
      description = "kube-apiserver LB endpoint"

      value = {
        endpoint = hcloud_server.lb.ipv4_address
      }
    }

    output "kubeone_hosts" {
      description = "Control plane endpoints to SSH to"

      value = {
        control_plane = {
          cluster_name         = var.cluster_name
          cloud_provider       = "hetzner"
          private_address      = [] # hetzner doesn't provide private addressed
          public_address       = hcloud_server.control_plane.*.ipv4_address
          ssh_agent_socket     = var.ssh_agent_socket
          ssh_port             = var.ssh_port
          ssh_private_key_file = var.ssh_private_key_file
          ssh_user             = var.ssh_username
        }
      }
    }

    output "kubeone_workers" {
      description = "Workers definitions, that will be transformed into MachineDeployment object"

      value = {
        # following outputs will be parsed by kubeone and automatically merged into
        # corresponding (by name) worker definition
        "${var.cluster_name}-pool1" = {
          replicas = 1
          providerSpec = {
            sshPublicKeys   = [file(var.ssh_public_key_file)]
            operatingSystem = var.worker_os
            operatingSystemSpec = {
              distUpgradeOnBoot = false
            }
            cloudProviderSpec = {
              # provider specific fields:
              # see example under `cloudProviderSpec` section at:
              # https://github.com/kubermatic/machine-controller/blob/master/examples/hetzner-machinedeployment.yaml
              serverType = var.worker_type
              location   = var.datacenter
              labels = {
                "${var.cluster_name}-workers" = "pool1"
              }
            }
          }
        }
      }
    }
